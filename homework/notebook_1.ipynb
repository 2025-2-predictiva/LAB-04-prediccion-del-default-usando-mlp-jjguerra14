{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3999b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load de data\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(zip_path):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path,\"r\") as z:\n",
    "            csv_filename=z.namelist()[0]\n",
    "\n",
    "            with z.open(csv_filename) as f:\n",
    "                df=pd.read_csv(f)\n",
    "        print(f\"File {csv_filename} uploaded succesfully\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\" Error loagind the file {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=load_data(\"../files/input/test_data.csv.zip\")\n",
    "train_data=load_data(\"../files/input/train_data.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape\n",
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "def data_cleaning(dataset, name=\"dataset\"):\n",
    "    dataset.rename(columns={\"default payment next month\":\"default\"}, inplace=True)\n",
    "    dataset.drop(columns=\"ID\",inplace=True)\n",
    "    dataset.dropna(inplace=True)\n",
    "    dataset.loc[dataset[\"EDUCATION\"]>4,\"EDUCATION\"]=4\n",
    "    print(f\"Data {name} cleaned successfully\")\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data_cleaning(train_data,\"train_data\")\n",
    "test_data=data_cleaning(test_data,\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c662780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "def split_data(train_data,test_data):\n",
    "    X_train=train_data.drop(columns=\"default\")\n",
    "    X_test=test_data.drop(columns=\"default\")\n",
    "\n",
    "    y_train=train_data[\"default\"]\n",
    "    y_test=test_data[\"default\"]\n",
    "\n",
    "    print(\"Correctly split dataset\")\n",
    "\n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def classification_pipeline(X_train, y_train, k_best_features=10):\n",
    "\n",
    "  \n",
    "    categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "    numeric_cols = [c for c in X_train.columns if c not in categorical_cols]\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),  \n",
    "            ('scaler', StandardScaler(), numeric_cols), \n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', SelectKBest(score_func=f_classif)),\n",
    "        ('pca', PCA()),    \n",
    "        ('mlp', MLPClassifier(max_iter=15000,random_state=42))  # Red neuronal MLP\n",
    "    ])\n",
    "\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07242081",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=classification_pipeline(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #4\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import numpy as np\n",
    "\n",
    "def Hyperparameter_optimization(model, X_train, y_train):\n",
    "\n",
    "    param_grid = {\n",
    "    'feature_selection__k': [20],\n",
    "    'pca__n_components': [None],  \n",
    "    'mlp__hidden_layer_sizes': [(50, 30, 40)], \n",
    "    'mlp__alpha': [0.26],  \n",
    "    'mlp__learning_rate_init': [0.001],  \n",
    "}\n",
    "\n",
    "\n",
    "    \n",
    "    #cv = KFold(n_splits=10, shuffle=True, random_state=132)\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='balanced_accuracy',\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        refit=True\n",
    "    )\n",
    "\n",
    "    # Ajustar el modelo\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Hyperparameter_optimization(model,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "\n",
    "#predicciones\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "#métricas para entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, zero_division=0)\n",
    "balanced_acc_train = balanced_accuracy_score(y_train, y_pred_train)\n",
    "recall_train = recall_score(y_train, y_pred_train, zero_division=0)\n",
    "f1_train = f1_score(y_train, y_pred_train, zero_division=0)\n",
    "\n",
    "#métricas para prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "balanced_acc_test = balanced_accuracy_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test, zero_division=0)\n",
    "f1_test = f1_score(y_test, y_pred_test, zero_division=0)\n",
    "\n",
    "#resultados\n",
    "print({'type': 'metrics', 'dataset': 'train',\n",
    "       'precision': round(precision_train, 4),\n",
    "       'balanced_accuracy': round(balanced_acc_train, 4),\n",
    "       'recall': round(recall_train, 4),\n",
    "       'f1_score': round(f1_train, 4)})\n",
    "\n",
    "print({'type': 'metrics', 'dataset': 'test',\n",
    "       'precision': round(precision_test, 4),\n",
    "       'balanced_accuracy': round(balanced_acc_test, 4),\n",
    "       'recall': round(recall_test, 4),\n",
    "       'f1_score': round(f1_test, 4)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d723bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "import gzip \n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_model(model,path=\"file path.gzip\"):\n",
    "    os.makedirs(os.path.dirname(path),exist_ok=True)\n",
    "\n",
    "    with gzip.open(path,\"wb\") as f:\n",
    "        pickle.dump(model,f)\n",
    "    print(\"Model saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model,\"../files/models/model.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import os\n",
    "import json\n",
    "\n",
    "def metrics_evaluation(model,X_train,y_train,X_test,y_test,data_set_name=\"train or test\"):\n",
    "        \n",
    "          if data_set_name == \"train\":\n",
    "               y_true = y_train\n",
    "               y_pred = model.predict(X_train)\n",
    "          elif data_set_name == \"test\":\n",
    "               y_true = y_test\n",
    "               y_pred = model.predict(X_test)\n",
    "          else:\n",
    "               raise ValueError(\"data_set_name must be 'train' o 'test'\")\n",
    "\n",
    "          #Metrics \n",
    "          precision = precision_score(y_true, y_pred)\n",
    "          balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "          recall = recall_score(y_true, y_pred)\n",
    "          f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "          return {\n",
    "          \"type\": \"metrics\",\n",
    "          'dataset': data_set_name,\n",
    "          'precision': float(precision),\n",
    "          'balanced_accuracy': float(balanced_accuracy),\n",
    "          'recall': float(recall),\n",
    "          'f1_score': float(f1)\n",
    "          }\n",
    "\n",
    "def load_metrics(path,metrics_train,metrics_test):\n",
    "      os.makedirs(os.path.dirname(path),exist_ok=True)\n",
    "\n",
    "      with open(path,'w',encoding='utf-8') as f:\n",
    "            json.dump(metrics_train,f)\n",
    "            f.write('\\n')\n",
    "            json.dump(metrics_test,f)\n",
    "            f.write('\\n')\n",
    "      print(\"Metrics Saved!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71619c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_train=metrics_evaluation(model,X_train,y_train,X_test,y_test,\"train\")\n",
    "metrics_test=metrics_evaluation(model,X_train,y_train,X_test,y_test,\"test\")\n",
    "\n",
    "load_metrics(\"../files/output/metrics.json\",metrics_train,metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a669b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cm_metrics(model,X_train,y_train,X_test,y_test,data_set_name=\"train or test\"):\n",
    "        \n",
    "        if data_set_name == \"train\":\n",
    "             y_true = y_train\n",
    "             y_pred = model.predict(X_train)\n",
    "        elif data_set_name == \"test\":\n",
    "             y_true = y_test\n",
    "             y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            raise ValueError(\"data_set_name must be 'train' o 'test'\")\n",
    "        \n",
    "        #Confusion matriz \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "          # Desempaquetar valores (para binario)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        return {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": data_set_name,\n",
    "        \"true_0\": {\"predicted_0\": int(tn), \"predicted_1\": int(fp)},\n",
    "        \"true_1\": {\"predicted_0\": int(fn), \"predicted_1\": int(tp)}\n",
    "        }\n",
    "\n",
    "def load_cm(path,cm_train,cm_test):\n",
    "      os.makedirs(os.path.dirname(path),exist_ok=True)\n",
    "\n",
    "      with open(path, 'a', encoding='utf-8') as f:\n",
    "        json.dump(cm_train, f)\n",
    "        f.write(\"\\n\")\n",
    "        json.dump(cm_test, f)\n",
    "        f.write(\"\\n\")\n",
    "        print(\"Metrics saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TN:\", tn, \"FP:\", fp, \"FN:\", fn, \"TP:\", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=cm_metrics(model,X_train,y_train,X_test,y_test,data_set_name=\"train\")\n",
    "\n",
    "cm_test=cm_metrics(model,X_train,y_train,X_test,y_test,data_set_name=\"test\")\n",
    "\n",
    "load_cm(\"../files/output/metrics.json\",cm_train,cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad14c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
